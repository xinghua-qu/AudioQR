{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c819b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/torchaudio/backend/utils.py:47: UserWarning: \"torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE\" flag is deprecated and will be removed in 0.9.0. Please remove the use of flag.\n",
      "  '\"torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE\" flag is deprecated and will be removed in 0.9.0. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import (\n",
    "  TextAudioLoader,\n",
    "  TextAudioCollate,\n",
    "  DistributedBucketSampler\n",
    ")\n",
    "from models import NFTAudio\n",
    "from mel_processing import mel_spectrogram_torch, spec_to_mel_torch\n",
    "from torchmetrics import SignalNoiseRatio\n",
    "import math\n",
    "from torch_audiomentations import Compose, Gain, PolarityInversion, AddBackgroundNoise, PitchShift, ApplyImpulseResponse, AddColoredNoise,HighPassFilter,LowPassFilter, Shift\n",
    "from pathlib import Path\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bfb980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NFTAudio(\n",
       "  (watermarker): Message_Encoder(\n",
       "    (conv_pre): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "      (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "      (2): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (6): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (7): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (8): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (9): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (10): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "      (11): ResBlock2(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "    (fc1): Linear(in_features=1000, out_features=6144, bias=True)\n",
       "  )\n",
       "  (hidden_wav): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=1000, bias=True)\n",
       "  )\n",
       "  (hidden_message): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=1000, bias=True)\n",
       "  )\n",
       "  (reconstructor): Message_Decoder(\n",
       "    (convs): ModuleList(\n",
       "      (0): Conv1d(1, 16, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "      (1): Conv1d(16, 64, kernel_size=(41,), stride=(4,), padding=(20,), groups=4)\n",
       "      (2): Conv1d(64, 256, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "      (3): Conv1d(256, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=64)\n",
       "    )\n",
       "    (conv_post): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       "  (augmenter): Compose(\n",
       "    (transforms): ModuleList(\n",
       "      (0): Gain()\n",
       "      (1): AddColoredNoise()\n",
       "      (2): PolarityInversion()\n",
       "      (3): Shift()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = 'five_agmt_run'\n",
    "step = 70000\n",
    "model_path = './logs/{}/NFTAudio_{}.pth'.format(run_name, step)\n",
    "wave_length = 8192\n",
    "msg_length = 100\n",
    "nft_model = NFTAudio(wave_length, msg_length).cuda(0)\n",
    "check_point = torch.load(model_path)\n",
    "# print(check_point)\n",
    "nft_model.load_state_dict(check_point['model'])\n",
    "nft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc05c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_save_path = './configs/ljs_base.json'\n",
    "with open(config_save_path, \"r\") as f:\n",
    "    data = f.read()\n",
    "import json\n",
    "from utils import HParams\n",
    "config = json.loads(data)\n",
    "hps = HParams(**config)\n",
    "hps.train.segment_size = 8192\n",
    "hps.train.eval_interval = 10000\n",
    "hps.train.log_interval = 500\n",
    "hps.train.batch_size = 2\n",
    "msg_dim = 100\n",
    "collate_fn = TextAudioCollate(msg_dim)\n",
    "eval_dataset = TextAudioLoader(hps.data.validation_files, hps.data, msg_dim)\n",
    "eval_loader = DataLoader(eval_dataset, num_workers=8, shuffle=True,\n",
    "    batch_size=hps.train.batch_size, pin_memory=True,\n",
    "    drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1af37812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 46.0\n",
      "3.409090909090909 48.20454545454545\n",
      "3.2535211267605635 48.690140845070424\n",
      "2.6842105263157894 47.14736842105263\n",
      "3.1875 48.848214285714285\n",
      "3.473684210526316 48.88721804511278\n",
      "3.698717948717949 48.333333333333336\n",
      "3.9943181818181817 49.00568181818182\n",
      "3.837696335078534 49.146596858638745\n",
      "4.033333333333333 50.01904761904762\n",
      "4.097777777777778 50.08\n",
      "4.171428571428572 49.76326530612245\n",
      "4.07089552238806 49.649253731343286\n",
      "4.132404181184669 49.57142857142857\n",
      "4.287539936102236 49.20447284345048\n",
      "4.27027027027027 49.174174174174176\n",
      "4.111731843575419 48.98882681564246\n",
      "4.0557029177718835 48.644562334217504\n",
      "4.002518891687657 48.40302267002519\n",
      "3.9683698296836982 48.57664233576642\n",
      "4.0233644859813085 48.36682242990654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "\n",
    "def audio_ptb(input_audio, ptb_type):\n",
    "    input_audio = input_audio.unsqueeze(1)\n",
    "    if ptb_type=='none':\n",
    "        new_audio = input_audio\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='gain':\n",
    "        agmt = Gain(min_gain_in_db=9,max_gain_in_db=10,p=1)\n",
    "        new_audio = agmt(input_audio, sample_rate=22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='noise':\n",
    "        new_audio = input_audio + 0.01*torch.randn_like(input_audio)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='inversion':\n",
    "        agmt = PolarityInversion(p=1)\n",
    "        new_audio = agmt(input_audio, sample_rate = 22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='shift':\n",
    "        agmt = Shift(min_shift=0.1,max_shift=0.5,shift_unit=\"fraction\",rollover=True,p=1)\n",
    "        new_audio = agmt(input_audio, sample_rate = 22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='env_background':\n",
    "        env_wav_dir = './background_noise/environment/'\n",
    "        agmt = AddBackgroundNoise(env_wav_dir, 1, p=1.0)\n",
    "        new_audio = agmt(input_audio, sample_rate = 22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='music_background':\n",
    "        env_wav_dir = './background_noise/music/'\n",
    "#         env_wav_dir = './test_audios/'\n",
    "        agmt = AddBackgroundNoise(env_wav_dir, 1, p=1.0)\n",
    "        new_audio = agmt(input_audio, sample_rate = 22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    if ptb_type=='rir':\n",
    "        rir_dir = './background_noise/rir_audios/'\n",
    "        agmt = ApplyImpulseResponse(p=1,ir_paths = rir_dir, sample_rate = 22050)\n",
    "        new_audio = agmt(input_audio, sample_rate = 22050)\n",
    "        new_audio = torch.clamp(new_audio, -1, 1)\n",
    "    return new_audio\n",
    "\n",
    "def SNR(watermarked, original):\n",
    "    # audio data type: tensor; dimension batch*8192.\n",
    "    snr = SignalNoiseRatio().cuda()\n",
    "    rate = snr(watermarked, original)\n",
    "    return rate    \n",
    "\n",
    "l1_loss  = torch.nn.L1Loss()\n",
    "wav_index = 0\n",
    "amplitude = np.iinfo(np.int16).max\n",
    "ori_errors = []\n",
    "ptb_errors = []\n",
    "SNR_list = []\n",
    "ptb_SNR_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (message,spec, spec_lengths, wav, wav_lengths) in enumerate(eval_loader):\n",
    "        spec    = spec.cuda(0)\n",
    "        wav, wav_lengths = wav.cuda(0), wav_lengths.cuda(0)\n",
    "        message = message.cuda(0)\n",
    "        wav = wav.squeeze()\n",
    "\n",
    "        watermarked_wav = torch.zeros_like(wav)# don't use empty like function\n",
    "        watermarked_wav.copy_(wav)\n",
    "        ptb_watermarked_wav = torch.zeros_like(wav)\n",
    "        ptb_watermarked_wav.copy_(wav)\n",
    "\n",
    "        error_rate = 0\n",
    "        ptb_error_rate = 0\n",
    "        watermark_times = wav_lengths[wav_index].item()//8192\n",
    "        for i in range(watermark_times):\n",
    "            wav_slice = torch.zeros_like(wav[wav_index,i*8192:(i+1)*8192])\n",
    "            wav_slice.copy_(wav[wav_index,i*8192:(i+1)*8192])\n",
    "            wav_slice = wav_slice.repeat(wav.size()[0],1)\n",
    "\n",
    "            message_new = torch.zeros_like(message[wav_index,:])\n",
    "            message_new.copy_(message[wav_index,:])\n",
    "            message_new = message_new.repeat(wav.size()[0],1)\n",
    "\n",
    "            recon_wav = torch.zeros_like(wav_slice)\n",
    "            recon_msg = torch.zeros_like(message_new)\n",
    "            recon_wav, recon_msg,_,_ = nft_model(wav_slice, message_new)\n",
    "            watermarked_wav[wav_index, i*8192:(i+1)*8192] = recon_wav[wav_index,:]\n",
    "\n",
    "            err = torch.abs(message[wav_index].squeeze().round() -recon_msg[wav_index].squeeze().round()).sum()\n",
    "            ori_errors.append(err.item())\n",
    "\n",
    "        entire_ori_mel = mel_spectrogram_torch(\n",
    "              wav[wav_index:wav_index+1,:].float(), \n",
    "              hps.data.filter_length, \n",
    "              hps.data.n_mel_channels, \n",
    "              hps.data.sampling_rate, \n",
    "              hps.data.hop_length, \n",
    "              hps.data.win_length, \n",
    "              hps.data.mel_fmin, \n",
    "              hps.data.mel_fmax\n",
    "            )\n",
    "\n",
    "        recon_mel = mel_spectrogram_torch(\n",
    "              watermarked_wav[wav_index:wav_index+1,:].float(), \n",
    "              hps.data.filter_length, \n",
    "              hps.data.n_mel_channels, \n",
    "              hps.data.sampling_rate, \n",
    "              hps.data.hop_length, \n",
    "              hps.data.win_length, \n",
    "              hps.data.mel_fmin, \n",
    "              hps.data.mel_fmax\n",
    "            )\n",
    "\n",
    "        delta_mel = mel_spectrogram_torch(\n",
    "              watermarked_wav[wav_index:wav_index+1,:].float()-wav[wav_index:wav_index+1,:].float(), \n",
    "              hps.data.filter_length, \n",
    "              hps.data.n_mel_channels, \n",
    "              hps.data.sampling_rate, \n",
    "              hps.data.hop_length, \n",
    "              hps.data.win_length, \n",
    "              hps.data.mel_fmin, \n",
    "              hps.data.mel_fmax\n",
    "            )\n",
    "        \n",
    "        ptb_type = 'rir' # 'none', 'noise', 'rir'\n",
    "        ptb_watermarked_wav = audio_ptb(watermarked_wav, ptb_type)\n",
    "        for i in range(watermark_times):\n",
    "            ptb_wav_slice = ptb_watermarked_wav[wav_index:wav_index+1,:,i*8192:(i+1)*8192]\n",
    "            ptb_recon_msg = nft_model.reconstructor(ptb_wav_slice)\n",
    "            ptb_err = torch.abs(message[wav_index].squeeze().round() -ptb_recon_msg[wav_index].squeeze().round()).sum()\n",
    "            ptb_errors.append(ptb_err.item())\n",
    "        ptb_watermarked_wav = ptb_watermarked_wav.squeeze()\n",
    "        print(np.mean(ori_errors), np.mean(ptb_errors))\n",
    "        snr = SNR(watermarked_wav[wav_index,:], wav[wav_index,:])\n",
    "        ptb_snr = SNR(ptb_watermarked_wav[wav_index,:], wav[wav_index,:])\n",
    "        SNR_list.append(snr.item())\n",
    "        ptb_SNR_list.append(ptb_snr.item())\n",
    "        save_ori_wav = np.asarray(wav[wav_index:wav_index+1,:].cpu().detach().numpy()*amplitude)[0]\n",
    "        save_wtm_wav = np.asarray(watermarked_wav[wav_index:wav_index+1,:].cpu().detach().numpy()*amplitude)[0]\n",
    "        save_ptb_wtm_wav = np.asarray(ptb_watermarked_wav[wav_index:wav_index+1,:].cpu().detach().numpy()*amplitude)[0]\n",
    "        delta = save_wtm_wav - save_ori_wav\n",
    "\n",
    "        model_dir = os.path.join(\"./results\", run_name)\n",
    "        log_path = '{}/evaluations/{}_ptb/'.format(model_dir, ptb_type)\n",
    "        if not os.path.exists(log_path):\n",
    "            os.makedirs(log_path)\n",
    "\n",
    "        write(\"{}/original_{}.wav\".format(log_path, batch_idx), 22050, save_ori_wav.astype(np.int16))\n",
    "        write(\"{}/watermarked_{}.wav\".format(log_path, batch_idx), 22050, save_wtm_wav.astype(np.int16))\n",
    "        write(\"{}/{}_ptb_watermarked_{}.wav\".format(log_path, ptb_type,batch_idx), 22050, save_ptb_wtm_wav.astype(np.int16))\n",
    "        \n",
    "        if batch_idx>=20:\n",
    "            break\n",
    "x = np.arange(0, delta.shape[0])\n",
    "plt.figure()\n",
    "plt.plot(x, save_ori_wav, label = 'Original')\n",
    "plt.plot(x, save_wtm_wav, label = 'Watermarked')\n",
    "plt.plot(x, delta, label = 'delta')\n",
    "plt.legend()\n",
    "plt.savefig('{}/wav_comparison_{}.pdf'.format(log_path, batch_idx),bbox_inches='tight', dpi=600)\n",
    "plt.close() \n",
    "\n",
    "x = np.arange(0, delta.shape[0])\n",
    "plt.figure()\n",
    "plt.plot(x, save_ori_wav, label = 'Original')\n",
    "plt.plot(x, save_wtm_wav, label = 'Watermarked')\n",
    "plt.plot(x, save_ptb_wtm_wav, label = '{}_Watermarked'.format(ptb_type))\n",
    "plt.legend()\n",
    "plt.savefig('{}/ptb_vs_nonptb_{}.pdf'.format(log_path, batch_idx),bbox_inches='tight', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "np.savetxt(\"{}/ber.csv\".format(log_path), ori_errors, delimiter =\", \", fmt ='%1.9f')\n",
    "np.savetxt(\"{}/{}_ptb_ber.csv\".format(log_path, ptb_type), ptb_errors, delimiter =\", \", fmt ='%1.9f')\n",
    "np.savetxt(\"{}/snr.csv\".format(log_path), SNR_list, delimiter =\", \", fmt ='%1.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c548f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
